{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import word2vec, fasttext\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the saved model and cleaned review data from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load('../data/300features_40minwords_10context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/labeledTrainData.tsv', header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/testData.tsv', header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cleantrainreviews.txt', 'rb') as fp:\n",
    "    clean_train_reviews = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cleantestreviews.txt', 'rb') as fp:\n",
    "    clean_test_reviews = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a start time, to see how long this takes, because clustering with KMeans can take a while. Setting $k$ equal to a fifth of the vocabulary size, which would give an average of 5 words per cluster. Wrapping the whole thing in an end time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means Clustering:  345.2002639770508 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "word_vectors = model.wv.vectors\n",
    "\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "kmeans = KMeans(n_clusters=int(num_clusters))\n",
    "\n",
    "idx = kmeans.fit_predict(word_vectors)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "elapsed = end - start\n",
    "\n",
    "print(\"Time taken for K Means Clustering: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.65"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it took about 5 minutes on my machine\n",
    "339 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Word/Index dictionary, mapping each vocabulary word to a cluster number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_centroid_mapping = dict(zip(model.wv.index2word, idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a loop to print out the words in the first 10 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "['scrap', 'piles']\n",
      "Cluster 1\n",
      "['andrea', 'carla', 'lena', 'ariel', 'teresa', 'pauline', 'iris', 'bliss', 'aileen', 'jen', 'su', 'rosa', 'mai', 'delilah', 'selena', 'flirt', 'anastasia', 'stacey', 'hagen', 'ilona', 'lilly', 'celine', 'lina', 'leila', 'celeste', 'miki', 'olga', 'alma', 'belial', 'kisna', 'auteuil', 'amira']\n",
      "Cluster 2\n",
      "['brigade']\n",
      "Cluster 3\n",
      "['altered', 'formed', 'expanded', 'discarded', 'omitted', 'unexplored']\n",
      "Cluster 4\n",
      "['retaining']\n",
      "Cluster 5\n",
      "['disgusting', 'outrageous', 'repulsive', 'vile', 'sickening', 'nauseating', 'revolting', 'distasteful', 'delirious', 'disrespectful', 'intolerable', 'repugnant']\n",
      "Cluster 6\n",
      "['owner', 'worker', 'district', 'employee', 'operator', 'escort', 'inmate', 'developer', 'irs']\n",
      "Cluster 7\n",
      "['kay', 'stevens', 'sue', 'carrie', 'collins', 'shields', 'banks', 'tyler', 'irving', 'katherine', 'carroll', 'carlos', 'palmer', 'thelma', 'fletcher', 'ava', 'eleanor', 'manson', 'roberta', 'tate', 'windsor', 'betsy', 'channing', 'lillard', 'jaime', 'forsyte', 'jasmine']\n",
      "Cluster 8\n",
      "['lord', 'knight', 'clone', 'barbarian', 'jackass', 'reservoir', 'solaris', 'superheroes', 'dun']\n",
      "Cluster 9\n",
      "['items', 'contestants', 'missions', 'tasks', 'options']\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(0,10):\n",
    "    print('Cluster', cluster)\n",
    "    \n",
    "    words = []\n",
    "    for i in range(0, len(word_centroid_mapping.values())):\n",
    "        if(list(word_centroid_mapping.values())[i] == cluster):\n",
    "            words.append(list(word_centroid_mapping.keys())[i])\n",
    "    \n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the clusters seem to make sense, like cluster 2 being military terms, and cluster 3 being all names, but some are just one-off clusters with only 1 word in them, like clusters 5 and 6 having 'finishes' and 'privileged', respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have clusters, also known as centroids, I can try out a \"bag-of-centroids\" model, which is essentially like Bag of Words, but uses clusters instead of just words. I start off by creating a custom function that will give me a numpy array for each review that has the number of features equal to the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_centroids(wordlist, word_centroid_mapping):\n",
    "\n",
    "    # The number of clusters is equal to the highest cluster index in the word/centroid map\n",
    "    num_centroids = max(word_centroid_mapping.values()) + 1\n",
    "\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_centroids = np.zeros(num_centroids, dtype=\"float32\")\n",
    "\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_mapping:\n",
    "            index = word_centroid_mapping[word]\n",
    "            bag_centroids[index] += 1\n",
    "\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I use the custom function from above to creat the bags of centroids for the review training and tests sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros((25000, int(num_clusters)), dtype=\"float32\")\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = bag_of_centroids(review, word_centroid_mapping)\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "test_centroids = np.zeros((25000, int(num_clusters)), dtype=\"float32\")\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = bag_of_centroids(review, word_centroid_mapping)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the newly created bags of centroids to train a random forest model again to compare with the previous attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_centroids, train.sentiment, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmodel.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84624"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmodel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the bag of centroids model did about as good as the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score on the training set: 0.9286933333333334\n",
      "Logistic Regression score on the test set: 0.85888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000, C=.3)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Logistic Regression score on the training set:\", lr.score(X_train, y_train))\n",
    "print(\"Logistic Regression score on the test set:\", lr.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
