{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the pickled sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sentences.txt', 'rb') as fp:\n",
    "    sentences = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795534"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating some logs of my various parameters, initializing the Word2Vec model, and training on the sentences data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hovanes/anaconda3/lib/python3.7/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "2019-05-03 14:58:45,255 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2019-05-03 14:58:45,258 : INFO : collecting all words and their counts\n",
      "2019-05-03 14:58:45,258 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-03 14:58:45,297 : INFO : PROGRESS: at sentence #10000, processed 225799 words, keeping 17773 word types\n",
      "2019-05-03 14:58:45,340 : INFO : PROGRESS: at sentence #20000, processed 451864 words, keeping 24940 word types\n",
      "2019-05-03 14:58:45,384 : INFO : PROGRESS: at sentence #30000, processed 671284 words, keeping 30022 word types\n",
      "2019-05-03 14:58:45,427 : INFO : PROGRESS: at sentence #40000, processed 897762 words, keeping 34337 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-03 14:58:45,472 : INFO : PROGRESS: at sentence #50000, processed 1116945 words, keeping 37748 word types\n",
      "2019-05-03 14:58:45,519 : INFO : PROGRESS: at sentence #60000, processed 1338366 words, keeping 40707 word types\n",
      "2019-05-03 14:58:45,563 : INFO : PROGRESS: at sentence #70000, processed 1561514 words, keeping 43317 word types\n",
      "2019-05-03 14:58:45,610 : INFO : PROGRESS: at sentence #80000, processed 1780803 words, keeping 45695 word types\n",
      "2019-05-03 14:58:45,653 : INFO : PROGRESS: at sentence #90000, processed 2004876 words, keeping 48112 word types\n",
      "2019-05-03 14:58:45,699 : INFO : PROGRESS: at sentence #100000, processed 2226855 words, keeping 50183 word types\n",
      "2019-05-03 14:58:45,742 : INFO : PROGRESS: at sentence #110000, processed 2446475 words, keeping 52056 word types\n",
      "2019-05-03 14:58:45,787 : INFO : PROGRESS: at sentence #120000, processed 2668648 words, keeping 54090 word types\n",
      "2019-05-03 14:58:45,831 : INFO : PROGRESS: at sentence #130000, processed 2894169 words, keeping 55819 word types\n",
      "2019-05-03 14:58:45,873 : INFO : PROGRESS: at sentence #140000, processed 3106859 words, keeping 57315 word types\n",
      "2019-05-03 14:58:45,919 : INFO : PROGRESS: at sentence #150000, processed 3332467 words, keeping 59023 word types\n",
      "2019-05-03 14:58:45,960 : INFO : PROGRESS: at sentence #160000, processed 3555121 words, keeping 60586 word types\n",
      "2019-05-03 14:58:46,007 : INFO : PROGRESS: at sentence #170000, processed 3778458 words, keeping 62044 word types\n",
      "2019-05-03 14:58:46,049 : INFO : PROGRESS: at sentence #180000, processed 3999008 words, keeping 63457 word types\n",
      "2019-05-03 14:58:46,095 : INFO : PROGRESS: at sentence #190000, processed 4224207 words, keeping 64756 word types\n",
      "2019-05-03 14:58:46,140 : INFO : PROGRESS: at sentence #200000, processed 4448298 words, keeping 66044 word types\n",
      "2019-05-03 14:58:46,184 : INFO : PROGRESS: at sentence #210000, processed 4669737 words, keeping 67343 word types\n",
      "2019-05-03 14:58:46,230 : INFO : PROGRESS: at sentence #220000, processed 4894637 words, keeping 68651 word types\n",
      "2019-05-03 14:58:46,277 : INFO : PROGRESS: at sentence #230000, processed 5117221 words, keeping 69912 word types\n",
      "2019-05-03 14:58:46,327 : INFO : PROGRESS: at sentence #240000, processed 5344761 words, keeping 71120 word types\n",
      "2019-05-03 14:58:46,378 : INFO : PROGRESS: at sentence #250000, processed 5558874 words, keeping 72302 word types\n",
      "2019-05-03 14:58:46,426 : INFO : PROGRESS: at sentence #260000, processed 5778770 words, keeping 73428 word types\n",
      "2019-05-03 14:58:46,475 : INFO : PROGRESS: at sentence #270000, processed 6000078 words, keeping 74718 word types\n",
      "2019-05-03 14:58:46,523 : INFO : PROGRESS: at sentence #280000, processed 6226010 words, keeping 76324 word types\n",
      "2019-05-03 14:58:46,569 : INFO : PROGRESS: at sentence #290000, processed 6449120 words, keeping 77791 word types\n",
      "2019-05-03 14:58:46,617 : INFO : PROGRESS: at sentence #300000, processed 6673746 words, keeping 79125 word types\n",
      "2019-05-03 14:58:46,663 : INFO : PROGRESS: at sentence #310000, processed 6899075 words, keeping 80435 word types\n",
      "2019-05-03 14:58:46,710 : INFO : PROGRESS: at sentence #320000, processed 7123912 words, keeping 81763 word types\n",
      "2019-05-03 14:58:46,757 : INFO : PROGRESS: at sentence #330000, processed 7345755 words, keeping 82985 word types\n",
      "2019-05-03 14:58:46,804 : INFO : PROGRESS: at sentence #340000, processed 7575223 words, keeping 84236 word types\n",
      "2019-05-03 14:58:46,850 : INFO : PROGRESS: at sentence #350000, processed 7798463 words, keeping 85382 word types\n",
      "2019-05-03 14:58:46,899 : INFO : PROGRESS: at sentence #360000, processed 8019094 words, keeping 86553 word types\n",
      "2019-05-03 14:58:46,951 : INFO : PROGRESS: at sentence #370000, processed 8246252 words, keeping 87665 word types\n",
      "2019-05-03 14:58:46,992 : INFO : PROGRESS: at sentence #380000, processed 8471464 words, keeping 88836 word types\n",
      "2019-05-03 14:58:47,038 : INFO : PROGRESS: at sentence #390000, processed 8701173 words, keeping 89865 word types\n",
      "2019-05-03 14:58:47,084 : INFO : PROGRESS: at sentence #400000, processed 8924041 words, keeping 90874 word types\n",
      "2019-05-03 14:58:47,128 : INFO : PROGRESS: at sentence #410000, processed 9145457 words, keeping 91839 word types\n",
      "2019-05-03 14:58:47,173 : INFO : PROGRESS: at sentence #420000, processed 9366524 words, keeping 92872 word types\n",
      "2019-05-03 14:58:47,216 : INFO : PROGRESS: at sentence #430000, processed 9594185 words, keeping 93893 word types\n",
      "2019-05-03 14:58:47,264 : INFO : PROGRESS: at sentence #440000, processed 9820789 words, keeping 94866 word types\n",
      "2019-05-03 14:58:47,310 : INFO : PROGRESS: at sentence #450000, processed 10044577 words, keeping 95997 word types\n",
      "2019-05-03 14:58:47,358 : INFO : PROGRESS: at sentence #460000, processed 10277317 words, keeping 97049 word types\n",
      "2019-05-03 14:58:47,406 : INFO : PROGRESS: at sentence #470000, processed 10505240 words, keeping 97894 word types\n",
      "2019-05-03 14:58:47,451 : INFO : PROGRESS: at sentence #480000, processed 10725756 words, keeping 98824 word types\n",
      "2019-05-03 14:58:47,496 : INFO : PROGRESS: at sentence #490000, processed 10952493 words, keeping 99833 word types\n",
      "2019-05-03 14:58:47,542 : INFO : PROGRESS: at sentence #500000, processed 11174042 words, keeping 100726 word types\n",
      "2019-05-03 14:58:47,587 : INFO : PROGRESS: at sentence #510000, processed 11399361 words, keeping 101660 word types\n",
      "2019-05-03 14:58:47,633 : INFO : PROGRESS: at sentence #520000, processed 11622685 words, keeping 102559 word types\n",
      "2019-05-03 14:58:47,675 : INFO : PROGRESS: at sentence #530000, processed 11847178 words, keeping 103361 word types\n",
      "2019-05-03 14:58:47,721 : INFO : PROGRESS: at sentence #540000, processed 12071804 words, keeping 104227 word types\n",
      "2019-05-03 14:58:47,767 : INFO : PROGRESS: at sentence #550000, processed 12297247 words, keeping 105095 word types\n",
      "2019-05-03 14:58:47,811 : INFO : PROGRESS: at sentence #560000, processed 12518512 words, keeping 105958 word types\n",
      "2019-05-03 14:58:47,858 : INFO : PROGRESS: at sentence #570000, processed 12747545 words, keeping 106749 word types\n",
      "2019-05-03 14:58:47,902 : INFO : PROGRESS: at sentence #580000, processed 12969078 words, keeping 107627 word types\n",
      "2019-05-03 14:58:47,947 : INFO : PROGRESS: at sentence #590000, processed 13194583 words, keeping 108463 word types\n",
      "2019-05-03 14:58:47,993 : INFO : PROGRESS: at sentence #600000, processed 13416783 words, keeping 109180 word types\n",
      "2019-05-03 14:58:48,038 : INFO : PROGRESS: at sentence #610000, processed 13637839 words, keeping 110054 word types\n",
      "2019-05-03 14:58:48,084 : INFO : PROGRESS: at sentence #620000, processed 13864196 words, keeping 110802 word types\n",
      "2019-05-03 14:58:48,129 : INFO : PROGRESS: at sentence #630000, processed 14088588 words, keeping 111573 word types\n",
      "2019-05-03 14:58:48,174 : INFO : PROGRESS: at sentence #640000, processed 14309227 words, keeping 112380 word types\n",
      "2019-05-03 14:58:48,219 : INFO : PROGRESS: at sentence #650000, processed 14534941 words, keeping 113159 word types\n",
      "2019-05-03 14:58:48,265 : INFO : PROGRESS: at sentence #660000, processed 14757724 words, keeping 113908 word types\n",
      "2019-05-03 14:58:48,311 : INFO : PROGRESS: at sentence #670000, processed 14981121 words, keeping 114606 word types\n",
      "2019-05-03 14:58:48,356 : INFO : PROGRESS: at sentence #680000, processed 15206063 words, keeping 115318 word types\n",
      "2019-05-03 14:58:48,401 : INFO : PROGRESS: at sentence #690000, processed 15428187 words, keeping 116095 word types\n",
      "2019-05-03 14:58:48,447 : INFO : PROGRESS: at sentence #700000, processed 15656856 words, keeping 116907 word types\n",
      "2019-05-03 14:58:48,490 : INFO : PROGRESS: at sentence #710000, processed 15879871 words, keeping 117561 word types\n",
      "2019-05-03 14:58:48,536 : INFO : PROGRESS: at sentence #720000, processed 16105146 words, keeping 118186 word types\n",
      "2019-05-03 14:58:48,581 : INFO : PROGRESS: at sentence #730000, processed 16331542 words, keeping 118919 word types\n",
      "2019-05-03 14:58:48,628 : INFO : PROGRESS: at sentence #740000, processed 16552584 words, keeping 119633 word types\n",
      "2019-05-03 14:58:48,671 : INFO : PROGRESS: at sentence #750000, processed 16770890 words, keeping 120260 word types\n",
      "2019-05-03 14:58:48,716 : INFO : PROGRESS: at sentence #760000, processed 16990281 words, keeping 120895 word types\n",
      "2019-05-03 14:58:48,761 : INFO : PROGRESS: at sentence #770000, processed 17217404 words, keeping 121668 word types\n",
      "2019-05-03 14:58:48,807 : INFO : PROGRESS: at sentence #780000, processed 17447550 words, keeping 122368 word types\n",
      "2019-05-03 14:58:48,853 : INFO : PROGRESS: at sentence #790000, processed 17674634 words, keeping 123031 word types\n",
      "2019-05-03 14:58:48,877 : INFO : collected 123469 word types from a corpus of 17797667 raw words and 795534 sentences\n",
      "2019-05-03 14:58:48,878 : INFO : Loading a fresh vocabulary\n",
      "2019-05-03 14:58:48,940 : INFO : min_count=40 retains 16488 unique words (13% of original 123469, drops 106981)\n",
      "2019-05-03 14:58:48,941 : INFO : min_count=40 leaves 17238582 word corpus (96% of original 17797667, drops 559085)\n",
      "2019-05-03 14:58:48,981 : INFO : deleting the raw counts dictionary of 123469 items\n",
      "2019-05-03 14:58:48,983 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2019-05-03 14:58:48,984 : INFO : downsampling leaves estimated 12749271 word corpus (74.0% of prior 17238582)\n",
      "2019-05-03 14:58:49,022 : INFO : estimated required memory for 16488 words and 300 dimensions: 47815200 bytes\n",
      "2019-05-03 14:58:49,023 : INFO : resetting layer weights\n",
      "2019-05-03 14:58:49,220 : INFO : training model with 10 workers on 16488 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-05-03 14:58:50,239 : INFO : EPOCH 1 - PROGRESS: at 11.84% examples, 1486389 words/s, in_qsize 17, out_qsize 2\n",
      "2019-05-03 14:58:51,253 : INFO : EPOCH 1 - PROGRESS: at 23.66% examples, 1480484 words/s, in_qsize 17, out_qsize 2\n",
      "2019-05-03 14:58:52,264 : INFO : EPOCH 1 - PROGRESS: at 34.71% examples, 1448654 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:58:53,267 : INFO : EPOCH 1 - PROGRESS: at 46.11% examples, 1450361 words/s, in_qsize 17, out_qsize 2\n",
      "2019-05-03 14:58:54,274 : INFO : EPOCH 1 - PROGRESS: at 57.90% examples, 1461194 words/s, in_qsize 17, out_qsize 2\n",
      "2019-05-03 14:58:55,286 : INFO : EPOCH 1 - PROGRESS: at 68.93% examples, 1449864 words/s, in_qsize 18, out_qsize 1\n",
      "2019-05-03 14:58:56,294 : INFO : EPOCH 1 - PROGRESS: at 80.42% examples, 1450485 words/s, in_qsize 18, out_qsize 1\n",
      "2019-05-03 14:58:57,301 : INFO : EPOCH 1 - PROGRESS: at 91.87% examples, 1451100 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:58:57,938 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-05-03 14:58:57,954 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-05-03 14:58:57,956 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-03 14:58:57,959 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-03 14:58:57,963 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-03 14:58:57,966 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-03 14:58:57,967 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-03 14:58:57,978 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-03 14:58:57,980 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-03 14:58:57,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-03 14:58:57,981 : INFO : EPOCH - 1 : training on 17797667 raw words (12749099 effective words) took 8.8s, 1456810 effective words/s\n",
      "2019-05-03 14:58:58,999 : INFO : EPOCH 2 - PROGRESS: at 11.61% examples, 1463389 words/s, in_qsize 20, out_qsize 0\n",
      "2019-05-03 14:59:00,006 : INFO : EPOCH 2 - PROGRESS: at 23.54% examples, 1481461 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:01,006 : INFO : EPOCH 2 - PROGRESS: at 34.94% examples, 1468636 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:02,019 : INFO : EPOCH 2 - PROGRESS: at 46.73% examples, 1473873 words/s, in_qsize 18, out_qsize 1\n",
      "2019-05-03 14:59:03,031 : INFO : EPOCH 2 - PROGRESS: at 58.46% examples, 1477160 words/s, in_qsize 17, out_qsize 2\n",
      "2019-05-03 14:59:04,038 : INFO : EPOCH 2 - PROGRESS: at 70.00% examples, 1474874 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:05,040 : INFO : EPOCH 2 - PROGRESS: at 81.70% examples, 1477288 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:06,049 : INFO : EPOCH 2 - PROGRESS: at 93.86% examples, 1484911 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:06,504 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-05-03 14:59:06,514 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-05-03 14:59:06,517 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-03 14:59:06,525 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-03 14:59:06,526 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-03 14:59:06,527 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-03 14:59:06,529 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-03 14:59:06,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-03 14:59:06,540 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-03 14:59:06,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-03 14:59:06,541 : INFO : EPOCH - 2 : training on 17797667 raw words (12747975 effective words) took 8.5s, 1491206 effective words/s\n",
      "2019-05-03 14:59:07,560 : INFO : EPOCH 3 - PROGRESS: at 11.90% examples, 1494845 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:08,568 : INFO : EPOCH 3 - PROGRESS: at 23.92% examples, 1503702 words/s, in_qsize 17, out_qsize 2\n",
      "2019-05-03 14:59:09,570 : INFO : EPOCH 3 - PROGRESS: at 35.45% examples, 1487260 words/s, in_qsize 20, out_qsize 1\n",
      "2019-05-03 14:59:10,570 : INFO : EPOCH 3 - PROGRESS: at 46.34% examples, 1463818 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:11,573 : INFO : EPOCH 3 - PROGRESS: at 57.26% examples, 1450633 words/s, in_qsize 18, out_qsize 1\n",
      "2019-05-03 14:59:12,575 : INFO : EPOCH 3 - PROGRESS: at 68.27% examples, 1442967 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:13,576 : INFO : EPOCH 3 - PROGRESS: at 79.46% examples, 1441115 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:14,583 : INFO : EPOCH 3 - PROGRESS: at 91.04% examples, 1444641 words/s, in_qsize 18, out_qsize 2\n",
      "2019-05-03 14:59:15,285 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-05-03 14:59:15,295 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-05-03 14:59:15,297 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-03 14:59:15,298 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-03 14:59:15,298 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-03 14:59:15,305 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-03 14:59:15,308 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-03 14:59:15,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-03 14:59:15,313 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-03 14:59:15,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-03 14:59:15,317 : INFO : EPOCH - 3 : training on 17797667 raw words (12748454 effective words) took 8.8s, 1454242 effective words/s\n",
      "2019-05-03 14:59:16,336 : INFO : EPOCH 4 - PROGRESS: at 11.95% examples, 1505038 words/s, in_qsize 20, out_qsize 0\n",
      "2019-05-03 14:59:17,347 : INFO : EPOCH 4 - PROGRESS: at 24.09% examples, 1513815 words/s, in_qsize 18, out_qsize 1\n",
      "2019-05-03 14:59:18,356 : INFO : EPOCH 4 - PROGRESS: at 36.29% examples, 1519245 words/s, in_qsize 18, out_qsize 1\n",
      "2019-05-03 14:59:19,358 : INFO : EPOCH 4 - PROGRESS: at 48.22% examples, 1521182 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:20,369 : INFO : EPOCH 4 - PROGRESS: at 60.08% examples, 1518222 words/s, in_qsize 17, out_qsize 2\n",
      "2019-05-03 14:59:21,380 : INFO : EPOCH 4 - PROGRESS: at 72.09% examples, 1518864 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:22,381 : INFO : EPOCH 4 - PROGRESS: at 84.18% examples, 1521315 words/s, in_qsize 20, out_qsize 0\n",
      "2019-05-03 14:59:23,382 : INFO : EPOCH 4 - PROGRESS: at 95.76% examples, 1515270 words/s, in_qsize 20, out_qsize 2\n",
      "2019-05-03 14:59:23,688 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-05-03 14:59:23,705 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-05-03 14:59:23,708 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-03 14:59:23,709 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-03 14:59:23,718 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-03 14:59:23,720 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-03 14:59:23,721 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-03 14:59:23,722 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-03 14:59:23,730 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-03 14:59:23,731 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-03 14:59:23,732 : INFO : EPOCH - 4 : training on 17797667 raw words (12751929 effective words) took 8.4s, 1517708 effective words/s\n",
      "2019-05-03 14:59:24,750 : INFO : EPOCH 5 - PROGRESS: at 10.81% examples, 1359665 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:25,755 : INFO : EPOCH 5 - PROGRESS: at 22.76% examples, 1430686 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:26,755 : INFO : EPOCH 5 - PROGRESS: at 33.72% examples, 1415672 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:27,763 : INFO : EPOCH 5 - PROGRESS: at 45.66% examples, 1441114 words/s, in_qsize 20, out_qsize 2\n",
      "2019-05-03 14:59:28,763 : INFO : EPOCH 5 - PROGRESS: at 57.63% examples, 1460171 words/s, in_qsize 16, out_qsize 0\n",
      "2019-05-03 14:59:29,781 : INFO : EPOCH 5 - PROGRESS: at 69.36% examples, 1462803 words/s, in_qsize 15, out_qsize 4\n",
      "2019-05-03 14:59:30,782 : INFO : EPOCH 5 - PROGRESS: at 80.64% examples, 1459040 words/s, in_qsize 19, out_qsize 0\n",
      "2019-05-03 14:59:31,801 : INFO : EPOCH 5 - PROGRESS: at 92.27% examples, 1459030 words/s, in_qsize 18, out_qsize 1\n",
      "2019-05-03 14:59:32,392 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-05-03 14:59:32,407 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-05-03 14:59:32,409 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-03 14:59:32,409 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-03 14:59:32,410 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-03 14:59:32,419 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-03 14:59:32,421 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-03 14:59:32,422 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-03 14:59:32,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-03 14:59:32,430 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-03 14:59:32,431 : INFO : EPOCH - 5 : training on 17797667 raw words (12747237 effective words) took 8.7s, 1466865 effective words/s\n",
      "2019-05-03 14:59:32,431 : INFO : training on a 88988335 raw words (63744694 effective words) took 43.2s, 1475210 effective words/s\n",
      "2019-05-03 14:59:32,432 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-05-03 14:59:32,573 : INFO : saving Word2Vec object under ../data/300features_40minwords_10context, separately None\n",
      "2019-05-03 14:59:32,573 : INFO : not storing attribute vectors_norm\n",
      "2019-05-03 14:59:32,574 : INFO : not storing attribute cum_table\n",
      "2019-05-03 14:59:32,574 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-03 14:59:32,900 : INFO : saved ../data/300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 10       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model.save('../data/300features_40minwords_10context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hovanes/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:730: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['man', 'woman', 'child', 'kitchen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the model knows that men, women, and children are more closely related than kitchens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.6142853498458862),\n",
       " ('lady', 0.595779538154602),\n",
       " ('monk', 0.5506272315979004),\n",
       " ('lad', 0.5482705235481262),\n",
       " ('guy', 0.5328831076622009),\n",
       " ('farmer', 0.5266038775444031),\n",
       " ('businessman', 0.5136960744857788),\n",
       " ('soldier', 0.5131512880325317),\n",
       " ('person', 0.5080838203430176),\n",
       " ('men', 0.5077749490737915)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7741910219192505),\n",
       " ('atrocious', 0.7451237440109253),\n",
       " ('horrible', 0.7385575771331787),\n",
       " ('dreadful', 0.7230740785598755),\n",
       " ('abysmal', 0.7135100364685059),\n",
       " ('horrendous', 0.6866555213928223),\n",
       " ('appalling', 0.6787832975387573),\n",
       " ('horrid', 0.6483640074729919),\n",
       " ('laughable', 0.6082620620727539),\n",
       " ('lousy', 0.5991135835647583)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('awful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the minimum word count to 40 gave me a total vocabulary of 16,488 words with 300 features each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16488, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom function to average all of the word vectors in a given paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom function to get the average feature vector for each of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(f\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions above to calculate the average feature vectors for the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/labeledTrainData.tsv', header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/testData.tsv', header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hovanes/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n",
      "Creating average feature vecs for test reviews\n",
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs(clean_train_reviews, model, num_features)\n",
    "\n",
    "print(\"Creating average feature vectorss for test reviews\")\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling the cleaned training and test reviews for later use in future notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cleantrainreviews.txt', 'wb') as fp:\n",
    "    pickle.dump(clean_train_reviews, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cleantestreviews.txt', 'wb') as fp:\n",
    "    pickle.dump(clean_test_reviews, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to try out some baseline models, I'll start off with RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trainDataVecs, train.sentiment, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a Random Forest to the labeled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmodel.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmodel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, RandomForest overfits on the training data, but doesn't do too bad on the test data. It is obviously much better than chance, but there is still a lot of room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel2 = rf.fit(trainDataVecs, train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rfmodel2.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('../data/Word2Vec_AverageVectors.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.review.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
